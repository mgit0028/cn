### Scrapyd的安装及使用
#### 1. 安装scrapyd
```
 pip install scrapyd 
```
#### 2. 安装setuptools
> 为什么要安装这个工具？

因为部署的应用需要打包成*.egg才能运行

官网地址：https://pypi.python.org/pypi/setuptools下载

```
pip install setuptools-38.5.2-py2.py3-none-any
```
#### 3. 部署工程

##### 3.1 创建项目
>工程下会有一个叫scrapy.cfg的文件，文件的内容如下：

```
[settings]
default = my_spider.settings

[deploy:demo]  # demo是指这个deploy的名称，自己命名，可以多个。（后面有用到） 
#url = http://localhost:6800/
project = my_spider  # 工程的名称
```
##### 3.2 启动scrapyd

> 在本工程下命令行下启动scrapyd

**注意：** 如果不先启动scrapyd就会无法部署工程

##### 3.3 部署项目
> 通过scrapyd-deploy部署，要求装一个scrapyd-client

```
pip install scrapyd-client
```
##### 3.4 配置scrapyd-deploy
在 %python_home%\Scripts下增加一个scrapyd-deploy.bat文件，内容如下：
```
@echo off 
"%python_home%\python.exe" "%python_home%\Scripts\scrapyd-deploy" %1 %2 %3 %4 %5 %6 %7 %8 %9
```
##### 3.5 使用scrapyd-deploy
```
scrapy-deploy demo  #demo就是scrapy.cfg中的名字
```

##### 4 运行Spider
```
curl http://localhost:6800/schedule.json -d project=项目名 -d spider=爬虫名
```

##### 5 查看效果
在浏览器输入localhost:6800

